# Ollama Code AI Assistant

AI-powered coding assistant that runs locally with Ollama.

## Features

- **Explain Code**: Get AI-powered explanations of selected code
- **Fix Errors**: Automatically fix errors with AI suggestions
- **Generate Tests**: Create comprehensive unit tests
- **Refactor Code**: Improve code quality with AI refactoring
- **Inline Completions**: GitHub Copilot-style autocomplete

## Requirements

- [Ollama](https://ollama.ai/) installed and running
- CodeLlama model: `ollama pull codellama:7b`

## Extension Settings

- `ollamaCode.model`: AI model to use (default: `codellama:7b`)
- `ollamaCode.apiUrl`: Ollama API URL (default: `http://localhost:11434`)
- `ollamaCode.maxTokens`: Maximum tokens for completions (default: 2048)
- `ollamaCode.enableInlineCompletions`: Enable inline completions (default: true)

## Usage

### Explain Code
1. Select code
2. Right-click → "Explain Code" (or Cmd+Shift+E)
3. View explanation in side panel

### Fix Errors
1. Position cursor on error
2. Press Cmd+. → "Fix with AI"
3. Apply suggested fix

### Generate Tests
1. Select function/class
2. Command Palette → "Ollama Code: Generate Tests"
3. Test file created automatically

## Privacy

All AI processing happens locally on your machine. No code is sent to external servers.

## License

MIT